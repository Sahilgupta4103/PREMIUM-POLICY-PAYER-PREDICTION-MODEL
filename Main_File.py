# -*- coding: utf-8 -*-
"""Main_File.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h4f74cbNI3g6YJQFSUJISybMAwRiH3Rp
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
label=LabelEncoder() 
from sklearn.preprocessing import StandardScaler 
Scaler=StandardScaler()
from sklearn.linear_model import LogisticRegression
logreg=LogisticRegression()
from sklearn.tree import DecisionTreeClassifier
dt=DecisionTreeClassifier()

df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/train.csv")

df.head()

df.shape

df.dtypes

df["perc_premium_paid_by_cash_credit"].plot.box()

df["perc_premium_paid_by_cash_credit"].plot.hist()

df["Income"].plot.box()

df["age_in_days"].plot.hist()

df.describe()

df.corr()

df.cov()

pd.crosstab(df["target"],df["residence_area_type"])

pd.crosstab(df["target"],df["no_of_premiums_paid"])

pd.crosstab(df["target"],df["Income"])

df.isnull().sum()

df.dropna(inplace=False).corr()

df.isnull().sum()

df['target'].corr(df["application_underwriting_score"].fillna(df["application_underwriting_score"].median(),inplace=False))

df['target'].corr(df["application_underwriting_score"].fillna(df["application_underwriting_score"].mean(),inplace=False))

df['target'].corr(df["application_underwriting_score"].fillna(df["application_underwriting_score"]))

df["Count_3-6_months_late"].value_counts()

df["Count_6-12_months_late"].value_counts()

df["Count_more_than_12_months_late"].value_counts()

def null(df):
  df["application_underwriting_score"].fillna(df["application_underwriting_score"].mean(),inplace=True)
  df["Count_3-6_months_late"].fillna(0,inplace=True)
  df["Count_6-12_months_late"].fillna(0,inplace=True)
  df["Count_more_than_12_months_late"].fillna(0,inplace=True)
  return df

null(df)

df.isnull().sum()

def transform (df):
  df["sourcing_channel"]=label.fit_transform(df["sourcing_channel"])
  df["residence_area_type"]=label.fit_transform(df["residence_area_type"])
  return df

transform (df)

bins = [0, 5475, 18250,33960]
group = ["Teenager", "Adult", "Old"]

df["Age Group"] = pd.cut(df["age_in_days"], bins, labels=group)

bins = [0, 100000, 468140]
group = ["Poor", "Rich"]
df["Fianancial Status"] = pd.cut(df["Income"], bins, labels=group)

df.head()

df=pd.get_dummies(df)

df.head()

train,test=train_test_split(df,test_size=0.2, random_state=112)

"""LOGISTIC REGRESSION MODEL

"""

x_train=train.drop("target",axis=1)
y_train=train["target"]
x_test=test.drop("target",axis=1)
y_test=test["target"]

x_train1=Scaler.fit_transform(x_train)
x_test1=Scaler.fit_transform(x_test)

logreg.fit(x_train1,y_train)

logreg.score(x_train1,y_train)

x_test1.shape

y_test.shape

logreg.score(x_test1,y_test)

result=logreg.predict(x_test)

result

"""DECISION TREE MODEL


> 






"""

x=df.drop("target",axis=1)
y=df["target"]

train_x,test_x,train_y,test_y=train_test_split(x,y,random_state=101,stratify=y)

train_x1=Scaler.fit_transform(train_x)
test_x1=Scaler.fit_transform(test_x)

train_y.value_counts()/ len(train_y)
test_y.value_counts()/ len(test_y)
dt.fit(train_x1,train_y)

dt.score(train_x1,train_y)

dt.score(test_x1,test_y)

dt.predict(train_x1)

dt.predict(test_x1)

test=pd.get_dummies(test)
test1=Scaler.fit_transform(test)

dt.predict_proba(test_x1)

x_test1.shape

pred_logreg=logreg.fit(x_test,y_test)

result=logreg.predict_proba(x_test)

result

"""KNEIGHBORS MODEL"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics

kc = KNeighborsClassifier(n_neighbors=5)
kc.fit(x_train,y_train)
pred=kc.predict(x_test)
result=metrics.accuracy_score(y_test,pred)
result

kc = KNeighborsClassifier(n_neighbors=4)
kc.fit(x_train,y_train)
pred=kc.predict(x_test)
result=metrics.accuracy_score(y_test,pred)
result

kc = KNeighborsClassifier(n_neighbors=6)
kc.fit(x_train,y_train)
pred=kc.predict(x_test)
result=metrics.accuracy_score(y_test,pred)
result

"""DEPLOYMENT

"""

import pickle
filename = 'model.pkl'
pickle.dump(logreg, open(filename, 'wb'))